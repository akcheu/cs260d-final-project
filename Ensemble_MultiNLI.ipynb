{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ensemble Models (ALBERT, BERT, RoBERTa) on MultiNLI Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Libraries and Check Hardware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JQ4M8Znd4_ep"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader, SequentialSampler, RandomSampler\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Dec 16 01:02:45 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  On   | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    28W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkpfPDS1Z8a8",
        "outputId": "3219bc62-f97b-499f-a28a-0379e1560f71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load MultiNLI Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-16 01:02:46.894443: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "from nlp import load_dataset\n",
        "train_data = load_dataset('multi_nli', split='train')\n",
        "val_data = load_dataset('multi_nli', split='validation_matched')\n",
        "test_data = load_dataset('multi_nli', split='validation_mismatched')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9vYZA1zq4_e7"
      },
      "outputs": [],
      "source": [
        "# Convert to DataFrame\n",
        "train_dataset = [item for item in train_data]\n",
        "val_dataset = [item for item in val_data]\n",
        "test_dataset = [item for item in test_data]\n",
        "train_df = pd.DataFrame(train_dataset)\n",
        "val_df = pd.DataFrame(val_dataset)\n",
        "test_df = pd.DataFrame(test_dataset)\n",
        "\n",
        "# Load in negation labels\n",
        "group_labels = pd.read_csv('metadata_preset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Organize dataframe\n",
        "\n",
        "train_group_labels = group_labels[group_labels['split'] == 0]['sentence2_has_negation']\n",
        "val_group_labels = group_labels[group_labels['split'] == 1]['sentence2_has_negation'].reset_index()['sentence2_has_negation']\n",
        "test_group_labels  = group_labels[group_labels['split'] == 2]['sentence2_has_negation'].reset_index()['sentence2_has_negation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = train_df.merge(train_group_labels, left_index=True, right_index=True)\n",
        "val_df = val_df.merge(val_group_labels, left_index=True, right_index=True)\n",
        "test_df = test_df.merge(test_group_labels, left_index=True, right_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = train_df.rename(columns={\"premise\": \"sentence1\", \"hypothesis\": \"sentence2\", \"label\": \"gold_label\", \"sentence2_has_negation\":\"negation\"})\n",
        "val_df = val_df.rename(columns={\"premise\": \"sentence1\", \"hypothesis\": \"sentence2\", \"label\": \"gold_label\", \"sentence2_has_negation\":\"negation\"})\n",
        "test_df = test_df.rename(columns={\"premise\": \"sentence1\", \"hypothesis\": \"sentence2\", \"label\": \"gold_label\", \"sentence2_has_negation\":\"negation\"})\n",
        "\n",
        "label_map = {0: 'entailment', 1: 'neutral', 2: 'contradiction'}\n",
        "train_df['gold_label'] = train_df['gold_label'].map(label_map)\n",
        "val_df['gold_label'] = val_df['gold_label'].map(label_map)\n",
        "test_df['gold_label'] = test_df['gold_label'].map(label_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_df['class'] = val_df['gold_label'].astype(str) + \"_\" + val_df['negation'].astype(str)\n",
        "train_df['class'] = train_df['gold_label'].astype(str) + \"_\" + train_df['negation'].astype(str)\n",
        "test_df['class'] = test_df['gold_label'].astype(str) + \"_\" + test_df['negation'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "class\n",
              "entailment_0       128042\n",
              "neutral_0          127135\n",
              "contradiction_0    109504\n",
              "contradiction_1     21399\n",
              "neutral_1            3765\n",
              "entailment_1         2857\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df['class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "class\n",
              "entailment_0       3388\n",
              "neutral_0          3036\n",
              "contradiction_0    2709\n",
              "contradiction_1     504\n",
              "entailment_1         91\n",
              "neutral_1            87\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_df['class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "class\n",
              "entailment_0       3391\n",
              "neutral_0          3044\n",
              "contradiction_0    2696\n",
              "contradiction_1     544\n",
              "neutral_1            85\n",
              "entailment_1         72\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df['class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3NgPYXBg4_e7"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.dropna()\n",
        "val_df = val_df.dropna()\n",
        "test_df = test_df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UMTQb1iMF54W"
      },
      "outputs": [],
      "source": [
        "train_df['sentence1'] = train_df['sentence1'].astype(str)\n",
        "train_df['sentence2'] = train_df['sentence2'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GMzPNmtpF8yg"
      },
      "outputs": [],
      "source": [
        "val_df['sentence1'] = val_df['sentence1'].astype(str)\n",
        "val_df['sentence2'] = val_df['sentence2'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df['sentence1'] = test_df['sentence1'].astype(str)\n",
        "test_df['sentence2'] = test_df['sentence2'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "diS3wCm14_e9"
      },
      "outputs": [],
      "source": [
        "train_df = train_df[(train_df['sentence1'].str.split().str.len() > 0) & (train_df['sentence2'].str.split().str.len() > 0)]\n",
        "val_df = val_df[(val_df['sentence1'].str.split().str.len() > 0) & (val_df['sentence2'].str.split().str.len() > 0)]\n",
        "test_df = test_df[(test_df['sentence1'].str.split().str.len() > 0) & (test_df['sentence2'].str.split().str.len() > 0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence2</th>\n",
              "      <th>gold_label</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>negation</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Product and geography are what make cream skim...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Conceptually cream skimming has two basic dime...</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>You lose the things to the following level if ...</td>\n",
              "      <td>entailment</td>\n",
              "      <td>you know during the season and i guess at at y...</td>\n",
              "      <td>0</td>\n",
              "      <td>entailment_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A member of my team will execute your orders w...</td>\n",
              "      <td>entailment</td>\n",
              "      <td>One of our number will carry out your instruct...</td>\n",
              "      <td>0</td>\n",
              "      <td>entailment_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This information belongs to them.</td>\n",
              "      <td>entailment</td>\n",
              "      <td>How do you know? All this is their information...</td>\n",
              "      <td>0</td>\n",
              "      <td>entailment_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The tennis shoes have a range of prices.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>yeah i tell you what though if you go price so...</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392697</th>\n",
              "      <td>California cannot do any better.</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>Clearly, California can - and must - do better.</td>\n",
              "      <td>0</td>\n",
              "      <td>contradiction_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392698</th>\n",
              "      <td>So many of the original buildings had been rep...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>It was once regarded as the most beautiful str...</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392699</th>\n",
              "      <td>The tradition of houseboats originated while t...</td>\n",
              "      <td>entailment</td>\n",
              "      <td>Houseboats are a beautifully preserved traditi...</td>\n",
              "      <td>0</td>\n",
              "      <td>entailment_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392700</th>\n",
              "      <td>The obituaries were beautiful and written in k...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Obituaries fondly recalled his on-air debates ...</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392701</th>\n",
              "      <td>My husband has been so overworked lately that ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>in that other you know uh that i should do it ...</td>\n",
              "      <td>0</td>\n",
              "      <td>neutral_0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>392702 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                sentence2     gold_label  \\\n",
              "0       Product and geography are what make cream skim...        neutral   \n",
              "1       You lose the things to the following level if ...     entailment   \n",
              "2       A member of my team will execute your orders w...     entailment   \n",
              "3                       This information belongs to them.     entailment   \n",
              "4                The tennis shoes have a range of prices.        neutral   \n",
              "...                                                   ...            ...   \n",
              "392697                   California cannot do any better.  contradiction   \n",
              "392698  So many of the original buildings had been rep...        neutral   \n",
              "392699  The tradition of houseboats originated while t...     entailment   \n",
              "392700  The obituaries were beautiful and written in k...        neutral   \n",
              "392701  My husband has been so overworked lately that ...        neutral   \n",
              "\n",
              "                                                sentence1  negation  \\\n",
              "0       Conceptually cream skimming has two basic dime...         0   \n",
              "1       you know during the season and i guess at at y...         0   \n",
              "2       One of our number will carry out your instruct...         0   \n",
              "3       How do you know? All this is their information...         0   \n",
              "4       yeah i tell you what though if you go price so...         0   \n",
              "...                                                   ...       ...   \n",
              "392697    Clearly, California can - and must - do better.         0   \n",
              "392698  It was once regarded as the most beautiful str...         0   \n",
              "392699  Houseboats are a beautifully preserved traditi...         0   \n",
              "392700  Obituaries fondly recalled his on-air debates ...         0   \n",
              "392701  in that other you know uh that i should do it ...         0   \n",
              "\n",
              "                  class  \n",
              "0             neutral_0  \n",
              "1          entailment_0  \n",
              "2          entailment_0  \n",
              "3          entailment_0  \n",
              "4             neutral_0  \n",
              "...                 ...  \n",
              "392697  contradiction_0  \n",
              "392698        neutral_0  \n",
              "392699     entailment_0  \n",
              "392700        neutral_0  \n",
              "392701        neutral_0  \n",
              "\n",
              "[392702 rows x 5 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Dataset Classes for Each Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Gk96lNh94_e_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from transformers import BertTokenizer, AlbertTokenizer\n",
        "\n",
        "class MNLIDataBert(Dataset):\n",
        "\n",
        "  def __init__(self, train_df, val_df, test_df):\n",
        "    self.label_dict = {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n",
        "    \n",
        "    # Add in negation classes (spurious feature)\n",
        "    self.negation_dict = {'entailment_0': 0, 'entailment_1': 1, 'contradiction_0': 2, 'contradiction_1': 3, 'neutral_0': 4, 'neutral_1': 5}\n",
        "\n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "    self.test_df = test_df\n",
        "\n",
        "    self.base_path = '/content/'\n",
        "    self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "    self.train_data = None\n",
        "    self.val_data = None\n",
        "    self.test_data = None\n",
        "    self.init_data()\n",
        "\n",
        "  def init_data(self):\n",
        "    self.train_data = self.load_data(self.train_df)\n",
        "    self.val_data = self.load_data(self.val_df)\n",
        "    self.test_data = self.load_data(self.test_df)\n",
        "\n",
        "  def load_data(self, df):\n",
        "    MAX_LEN = 512\n",
        "    token_ids = []\n",
        "    mask_ids = []\n",
        "    seg_ids = []\n",
        "    y = []\n",
        "    n = []\n",
        "\n",
        "    premise_list = df['sentence1'].to_list()\n",
        "    hypothesis_list = df['sentence2'].to_list()\n",
        "    label_list = df['gold_label'].to_list()\n",
        "    negation_list = df['class'].to_list()\n",
        "\n",
        "    for (premise, hypothesis, label, negation) in zip(premise_list, hypothesis_list, label_list, negation_list):\n",
        "      premise_id = self.tokenizer.encode(premise, add_special_tokens = False)\n",
        "      hypothesis_id = self.tokenizer.encode(hypothesis, add_special_tokens = False)\n",
        "      pair_token_ids = [self.tokenizer.cls_token_id] + premise_id + [self.tokenizer.sep_token_id] + hypothesis_id + [self.tokenizer.sep_token_id]\n",
        "      premise_len = len(premise_id)\n",
        "      hypothesis_len = len(hypothesis_id)\n",
        "\n",
        "      segment_ids = torch.tensor([0] * (premise_len + 2) + [1] * (hypothesis_len + 1)) \n",
        "      attention_mask_ids = torch.tensor([1] * (premise_len + hypothesis_len + 3)) \n",
        "\n",
        "      token_ids.append(torch.tensor(pair_token_ids))\n",
        "      seg_ids.append(segment_ids)\n",
        "      mask_ids.append(attention_mask_ids)\n",
        "      y.append(self.label_dict[label])\n",
        "      n.append(self.negation_dict[negation])\n",
        "    \n",
        "    token_ids = pad_sequence(token_ids, batch_first=True)\n",
        "    mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
        "    seg_ids = pad_sequence(seg_ids, batch_first=True)\n",
        "    y = torch.tensor(y)\n",
        "    n = torch.tensor(n)\n",
        "    dataset = TensorDataset(token_ids, mask_ids, seg_ids, y, n)\n",
        "    print(len(dataset))\n",
        "    return dataset\n",
        "\n",
        "  def get_data_loaders(self, batch_size=16, shuffle=False):\n",
        "    train_loader = DataLoader(\n",
        "      self.train_data,\n",
        "      shuffle=shuffle,\n",
        "      batch_size=batch_size,\n",
        "      sampler=SequentialSampler(self.train_data)\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "      self.val_data,\n",
        "      shuffle=shuffle,\n",
        "      batch_size=batch_size,\n",
        "      sampler=SequentialSampler(self.val_data)\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "      self.test_data,\n",
        "      shuffle=shuffle,\n",
        "      batch_size=batch_size,\n",
        "      sampler=SequentialSampler(self.test_data)\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from transformers import BertTokenizer, AlbertTokenizer\n",
        "\n",
        "class MNLIDataAlbert(Dataset):\n",
        "\n",
        "  def __init__(self, train_df, val_df, test_df):\n",
        "    self.label_dict = {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n",
        "\n",
        "    # Add in negation classes (spurious feature)\n",
        "    self.negation_dict = {'entailment_0': 0, 'entailment_1': 1, 'contradiction_0': 2, 'contradiction_1': 3, 'neutral_0': 4, 'neutral_1': 5}\n",
        "\n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "    self.test_df = test_df\n",
        "\n",
        "    self.base_path = '/content/'\n",
        "    self.tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2', do_lower_case=True)\n",
        "    self.train_data = None\n",
        "    self.val_data = None\n",
        "    self.test_data = None\n",
        "    self.init_data()\n",
        "\n",
        "  def init_data(self):\n",
        "    self.train_data = self.load_data(self.train_df)\n",
        "    self.val_data = self.load_data(self.val_df)\n",
        "    self.test_data = self.load_data(self.test_df)\n",
        "\n",
        "  def load_data(self, df):\n",
        "    MAX_LEN = 512\n",
        "    token_ids = []\n",
        "    mask_ids = []\n",
        "    seg_ids = []\n",
        "    y = []\n",
        "    n = []\n",
        "\n",
        "    premise_list = df['sentence1'].to_list()\n",
        "    hypothesis_list = df['sentence2'].to_list()\n",
        "    label_list = df['gold_label'].to_list()\n",
        "    negation_list = df['class'].to_list()\n",
        "\n",
        "    for (premise, hypothesis, label, negation) in zip(premise_list, hypothesis_list, label_list, negation_list):\n",
        "      premise_id = self.tokenizer.encode(premise, add_special_tokens = False)\n",
        "      hypothesis_id = self.tokenizer.encode(hypothesis, add_special_tokens = False)\n",
        "      pair_token_ids = [self.tokenizer.cls_token_id] + premise_id + [self.tokenizer.sep_token_id] + hypothesis_id + [self.tokenizer.sep_token_id]\n",
        "      premise_len = len(premise_id)\n",
        "      hypothesis_len = len(hypothesis_id)\n",
        "\n",
        "      segment_ids = torch.tensor([0] * (premise_len + 2) + [1] * (hypothesis_len + 1)) \n",
        "      attention_mask_ids = torch.tensor([1] * (premise_len + hypothesis_len + 3)) \n",
        "\n",
        "      token_ids.append(torch.tensor(pair_token_ids))\n",
        "      seg_ids.append(segment_ids)\n",
        "      mask_ids.append(attention_mask_ids)\n",
        "      y.append(self.label_dict[label])\n",
        "      n.append(self.negation_dict[negation])\n",
        "    \n",
        "    token_ids = pad_sequence(token_ids, batch_first=True)\n",
        "    mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
        "    seg_ids = pad_sequence(seg_ids, batch_first=True)\n",
        "    y = torch.tensor(y)\n",
        "    n = torch.tensor(n)\n",
        "    dataset = TensorDataset(token_ids, mask_ids, seg_ids, y, n)\n",
        "    print(len(dataset))\n",
        "    return dataset\n",
        "\n",
        "  def get_data_loaders(self, batch_size=16, shuffle=False):\n",
        "    train_loader = DataLoader(\n",
        "      self.train_data,\n",
        "      shuffle=shuffle,\n",
        "      batch_size=batch_size,\n",
        "      sampler=SequentialSampler(self.train_data)\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "      self.val_data,\n",
        "      shuffle=shuffle,\n",
        "      batch_size=batch_size,\n",
        "      sampler=SequentialSampler(self.val_data)\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "      self.test_data,\n",
        "      shuffle=shuffle,\n",
        "      batch_size=batch_size,\n",
        "      sampler=SequentialSampler(self.test_data)\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from transformers import BertTokenizer, AlbertTokenizer, RobertaTokenizer\n",
        "\n",
        "class MNLIDataRoberta(Dataset):\n",
        "\n",
        "  def __init__(self, train_df, val_df, test_df):\n",
        "    self.label_dict = {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n",
        "\n",
        "    # Add in negation classes (spurious feature)\n",
        "    self.negation_dict = {'entailment_0': 0, 'entailment_1': 1, 'contradiction_0': 2, 'contradiction_1': 3, 'neutral_0': 4, 'neutral_1': 5}\n",
        "\n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "    self.test_df = test_df\n",
        "\n",
        "    self.base_path = '/content/'\n",
        "    self.tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "    self.train_data = None\n",
        "    self.val_data = None\n",
        "    self.test_data = None\n",
        "    self.init_data()\n",
        "\n",
        "  def init_data(self):\n",
        "    self.train_data = self.load_data(self.train_df)\n",
        "    self.val_data = self.load_data(self.val_df)\n",
        "    self.test_data = self.load_data(self.test_df)\n",
        "\n",
        "  def load_data(self, df):\n",
        "    MAX_LEN = 512\n",
        "    token_ids = []\n",
        "    mask_ids = []\n",
        "    y = []\n",
        "    n = []\n",
        "\n",
        "    premise_list = df['sentence1'].to_list()\n",
        "    hypothesis_list = df['sentence2'].to_list()\n",
        "    label_list = df['gold_label'].to_list()\n",
        "    negation_list = df['class'].to_list()\n",
        "\n",
        "    for (premise, hypothesis, label, negation) in zip(premise_list, hypothesis_list, label_list, negation_list):\n",
        "      premise_id = self.tokenizer.encode(premise, add_special_tokens = False)\n",
        "      hypothesis_id = self.tokenizer.encode(hypothesis, add_special_tokens = False)\n",
        "      pair_token_ids = [self.tokenizer.bos_token_id] + premise_id + [self.tokenizer.sep_token_id] + hypothesis_id + [self.tokenizer.eos_token_id]\n",
        "\n",
        "      premise_len = len(premise_id)\n",
        "      hypothesis_len = len(hypothesis_id)\n",
        "\n",
        "      attention_mask_ids = torch.tensor([1] * (premise_len + hypothesis_len + 3))  \n",
        "\n",
        "      token_ids.append(torch.tensor(pair_token_ids))\n",
        "      mask_ids.append(attention_mask_ids)\n",
        "      y.append(self.label_dict[label])\n",
        "      n.append(self.negation_dict[negation])\n",
        "    \n",
        "    token_ids = pad_sequence(token_ids, batch_first=True)\n",
        "    mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
        "    y = torch.tensor(y)\n",
        "    n = torch.tensor(n)\n",
        "    dataset = TensorDataset(token_ids, mask_ids, y, n)\n",
        "    print(len(dataset))\n",
        "    return dataset\n",
        "\n",
        "  def get_data_loaders(self, batch_size=32, shuffle=False):\n",
        "    train_loader = DataLoader(\n",
        "      self.train_data,\n",
        "      shuffle=shuffle,\n",
        "      batch_size=batch_size,\n",
        "      sampler=SequentialSampler(self.train_data)\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "      self.val_data,\n",
        "      shuffle=shuffle,\n",
        "      batch_size=batch_size,\n",
        "      sampler=SequentialSampler(self.val_data)\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "      self.test_data,\n",
        "      shuffle=shuffle,\n",
        "      batch_size=32,\n",
        "      sampler=SequentialSampler(self.test_data)\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "md52P1z14_e_",
        "outputId": "3421aec1-128f-4589-874d-a82372138365"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "9815\n",
            "9832\n",
            "1\n",
            "9815\n",
            "9832\n",
            "1\n",
            "9815\n",
            "9832\n"
          ]
        }
      ],
      "source": [
        "# Only need validation and test sets, since we have trained model already\n",
        "bert_mnli_dataset = MNLIDataBert(train_df[:1], val_df[:], test_df[:])\n",
        "albert_mnli_dataset = MNLIDataAlbert(train_df[:1], val_df[:], test_df[:])\n",
        "roberta_mnli_dataset = MNLIDataRoberta(train_df[:1], val_df[:], test_df[:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "_, bert_val_loader, bert_test_loader = bert_mnli_dataset.get_data_loaders(batch_size=8)\n",
        "_, albert_val_loader, albert_test_loader = albert_mnli_dataset.get_data_loaders(batch_size=8)\n",
        "_, roberta_val_loader, roberta_test_loader = roberta_mnli_dataset.get_data_loaders(batch_size=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Full Model (393K) checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOdc4Cs2DEjt",
        "outputId": "98759f4f-ead1-4b1d-c20c-0ce4996de3ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, AlbertForSequenceClassification, RobertaForSequenceClassification\n",
        "\n",
        "bert = BertForSequenceClassification.from_pretrained('/home/allen/other/BERT_Full', num_labels=3)\n",
        "bert.to(device)\n",
        "albert = AlbertForSequenceClassification.from_pretrained(\"/home/allen/other/ALBERT_Full\", num_labels=3)\n",
        "albert.to(device)\n",
        "roberta = RobertaForSequenceClassification.from_pretrained(\"/home/allen/other/RoBERTa_Full\", num_labels=3)\n",
        "roberta.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate Individual Model Validation Accuracies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "negation_dict = {0: 'entailment_0',\n",
        " 1: 'entailment_1',\n",
        " 2: 'contradiction_0',\n",
        " 3: 'contradiction_1',\n",
        " 4: 'neutral_0',\n",
        " 5: 'neutral_1'}\n",
        "\n",
        "def multi_acc(y_pred, y_test):\n",
        "  acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
        "  return acc\n",
        "\n",
        "def evaluate_bert(bert, bert_val_loader):  \n",
        "  bert.eval()\n",
        "  total_val_acc  = 0\n",
        "  total_val_loss = 0\n",
        "\n",
        "  class_correct_predictions = defaultdict(int)\n",
        "  class_total_predictions = defaultdict(int)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch_bert in tqdm(bert_val_loader, total=len(bert_val_loader)):\n",
        "      # BERT\n",
        "      b_pair_token_ids, b_mask_ids, b_seg_ids, b_y, b_n = batch_bert\n",
        "      b_pair_token_ids = b_pair_token_ids.to(device)\n",
        "      b_mask_ids = b_mask_ids.to(device)\n",
        "      b_seg_ids = b_seg_ids.to(device)\n",
        "      b_labels = b_y.to(device)\n",
        "      b_negation = b_n.to(device)\n",
        "\n",
        "      b_loss, b_logits = bert(b_pair_token_ids, \n",
        "                            token_type_ids=b_seg_ids, \n",
        "                            attention_mask=b_mask_ids, \n",
        "                            labels=b_labels).values()\n",
        "      b_probs = torch.softmax(b_logits, dim=1)\n",
        "      preds = torch.argmax(b_probs, dim=1)\n",
        "\n",
        "      # Compute accuracy per negation class\n",
        "      for i in range(len(b_labels)):\n",
        "        class_identifier = negation_dict[int(b_negation[i].item())]\n",
        "        class_correct_predictions[class_identifier] += int(preds[i] == b_labels[i])\n",
        "        class_total_predictions[class_identifier] += 1\n",
        "\n",
        "      correct_preds = (preds == b_labels.to(device)).sum().item() / float(b_labels.size(0))\n",
        "      total_val_acc += correct_preds\n",
        "      total_val_loss += (b_loss.item())\n",
        "\n",
        "    val_acc  = total_val_acc/len(bert_val_loader)\n",
        "    val_loss = total_val_loss/len(bert_val_loader)\n",
        "  \n",
        "    print(f'Test_loss: {val_loss:.4f} Test_acc: {val_acc:.4f}')\n",
        "\n",
        "    for class_id, correct_count in sorted(class_correct_predictions.items()):\n",
        "      accuracy = correct_count / class_total_predictions[class_id]\n",
        "      print(f\"--- Class {class_id} accuracy: {accuracy:.4f}]\")\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1229/1229 [00:37<00:00, 32.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_loss: 0.5649 Test_acc: 0.8315\n",
            "--- Class contradiction_0 accuracy: 0.8179]\n",
            "--- Class contradiction_1 accuracy: 0.9430]\n",
            "--- Class entailment_0 accuracy: 0.8493]\n",
            "--- Class entailment_1 accuracy: 0.7222]\n",
            "--- Class neutral_0 accuracy: 0.8121]\n",
            "--- Class neutral_1 accuracy: 0.6235]\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate_bert(bert, bert_test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1227/1227 [00:42<00:00, 29.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_loss: 0.5864 Test_acc: 0.8329\n",
            "--- Class contradiction_0 accuracy: 0.8357]\n",
            "--- Class contradiction_1 accuracy: 0.9464]\n",
            "--- Class entailment_0 accuracy: 0.8297]\n",
            "--- Class entailment_1 accuracy: 0.7802]\n",
            "--- Class neutral_0 accuracy: 0.8221]\n",
            "--- Class neutral_1 accuracy: 0.6437]\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate_bert(bert, bert_val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ALBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "negation_dict = {0: 'entailment_0',\n",
        " 1: 'entailment_1',\n",
        " 2: 'contradiction_0',\n",
        " 3: 'contradiction_1',\n",
        " 4: 'neutral_0',\n",
        " 5: 'neutral_1'}\n",
        "\n",
        "def multi_acc(y_pred, y_test):\n",
        "  acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
        "  return acc\n",
        "\n",
        "def evaluate_albert(albert, albert_val_loader):  \n",
        "  albert.eval()\n",
        "  total_val_acc  = 0\n",
        "  total_val_loss = 0\n",
        "\n",
        "  class_correct_predictions = defaultdict(int)\n",
        "  class_total_predictions = defaultdict(int)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch_albert in tqdm(albert_val_loader, total=len(albert_val_loader)):      \n",
        "      # ALBERT\n",
        "      a_pair_token_ids, a_mask_ids, a_seg_ids, a_y, a_n = batch_albert\n",
        "      a_pair_token_ids = a_pair_token_ids.to(device)\n",
        "      a_mask_ids = a_mask_ids.to(device)\n",
        "      a_seg_ids = a_seg_ids.to(device)\n",
        "      a_labels = a_y.to(device)\n",
        "      a_negation = a_n.to(device)\n",
        "\n",
        "      a_loss, a_logits = albert(a_pair_token_ids, \n",
        "                                token_type_ids=a_seg_ids, \n",
        "                                attention_mask=a_mask_ids, \n",
        "                                labels=a_labels).values()\n",
        "      a_probs = torch.softmax(a_logits, dim=1)\n",
        "      preds = torch.argmax(a_probs, dim=1)\n",
        "\n",
        "      # Compute accuracy per negation class\n",
        "      for i in range(len(a_labels)):\n",
        "        class_identifier = negation_dict[int(a_negation[i].item())]\n",
        "        class_correct_predictions[class_identifier] += int(preds[i] == a_labels[i])\n",
        "        class_total_predictions[class_identifier] += 1\n",
        "\n",
        "      correct_preds = (preds == a_labels.to(device)).sum().item() / float(a_labels.size(0))\n",
        "      total_val_acc += correct_preds\n",
        "      total_val_loss += a_loss.item()\n",
        "\n",
        "    val_acc  = total_val_acc/len(albert_val_loader)\n",
        "    val_loss = total_val_loss/len(albert_val_loader)\n",
        "  \n",
        "    print(f'Test_loss: {val_loss:.4f} Test_acc: {val_acc:.4f}')\n",
        "\n",
        "    for class_id, correct_count in sorted(class_correct_predictions.items()):\n",
        "      accuracy = correct_count / class_total_predictions[class_id]\n",
        "      print(f\"--- Class {class_id} accuracy: {accuracy:.4f}]\")\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1229/1229 [00:44<00:00, 27.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_loss: 0.4565 Test_acc: 0.8459\n",
            "--- Class contradiction_0 accuracy: 0.8349]\n",
            "--- Class contradiction_1 accuracy: 0.9688]\n",
            "--- Class entailment_0 accuracy: 0.8596]\n",
            "--- Class entailment_1 accuracy: 0.7917]\n",
            "--- Class neutral_0 accuracy: 0.8249]\n",
            "--- Class neutral_1 accuracy: 0.6588]\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate_albert(albert, albert_test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1227/1227 [00:50<00:00, 24.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_loss: 0.4549 Test_acc: 0.8451\n",
            "--- Class contradiction_0 accuracy: 0.8365]\n",
            "--- Class contradiction_1 accuracy: 0.9464]\n",
            "--- Class entailment_0 accuracy: 0.8403]\n",
            "--- Class entailment_1 accuracy: 0.7582]\n",
            "--- Class neutral_0 accuracy: 0.8475]\n",
            "--- Class neutral_1 accuracy: 0.7241]\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate_albert(albert, albert_val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "negation_dict = {0: 'entailment_0',\n",
        " 1: 'entailment_1',\n",
        " 2: 'contradiction_0',\n",
        " 3: 'contradiction_1',\n",
        " 4: 'neutral_0',\n",
        " 5: 'neutral_1'}\n",
        "\n",
        "def multi_acc(y_pred, y_test):\n",
        "  acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
        "  return acc\n",
        "\n",
        "def evaluate_roberta(roberta, roberta_val_loader):  \n",
        "  roberta.eval()\n",
        "  total_val_acc  = 0\n",
        "  total_val_loss = 0\n",
        "\n",
        "  class_correct_predictions = defaultdict(int)\n",
        "  class_total_predictions = defaultdict(int)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch_roberta in tqdm(roberta_val_loader, total=len(roberta_val_loader)):\n",
        "      r_pair_token_ids, r_mask_ids, r_y, r_n = batch_roberta\n",
        "      r_pair_token_ids = r_pair_token_ids.to(device)\n",
        "      r_mask_ids = r_mask_ids.to(device)\n",
        "      r_labels = r_y.to(device)\n",
        "      r_negation = r_n.to(device)\n",
        "\n",
        "      r_loss, r_logits = roberta(r_pair_token_ids, \n",
        "                                attention_mask=r_mask_ids, \n",
        "                                labels=r_labels).values()\n",
        "      r_probs = torch.softmax(r_logits, dim=1)\n",
        "      \n",
        "      preds = torch.argmax(r_probs, dim=1)\n",
        "\n",
        "      # Compute accuracy per negation class\n",
        "      for i in range(len(r_labels)):\n",
        "        class_identifier = negation_dict[int(r_negation[i].item())]\n",
        "        class_correct_predictions[class_identifier] += int(preds[i] == r_labels[i])\n",
        "        class_total_predictions[class_identifier] += 1\n",
        "\n",
        "      correct_preds = (preds == r_labels.to(device)).sum().item() / float(r_labels.size(0))\n",
        "      total_val_acc += correct_preds\n",
        "      total_val_loss += r_loss.item()\n",
        "\n",
        "    val_acc  = total_val_acc/len(roberta_val_loader)\n",
        "    val_loss = total_val_loss/len(roberta_val_loader)\n",
        "  \n",
        "    print(f'Test_loss: {val_loss:.4f} Test_acc: {val_acc:.4f}')\n",
        "\n",
        "    for class_id, correct_count in sorted(class_correct_predictions.items()):\n",
        "      accuracy = correct_count / class_total_predictions[class_id]\n",
        "      print(f\"--- Class {class_id} accuracy: {accuracy:.4f}]\")\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1229/1229 [00:39<00:00, 30.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_loss: 0.3754 Test_acc: 0.8737\n",
            "--- Class contradiction_0 accuracy: 0.8709]\n",
            "--- Class contradiction_1 accuracy: 0.9798]\n",
            "--- Class entailment_0 accuracy: 0.8924]\n",
            "--- Class entailment_1 accuracy: 0.8194]\n",
            "--- Class neutral_0 accuracy: 0.8407]\n",
            "--- Class neutral_1 accuracy: 0.7647]\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate_roberta(roberta, roberta_test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1227/1227 [00:40<00:00, 30.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_loss: 0.3723 Test_acc: 0.8754\n",
            "--- Class contradiction_0 accuracy: 0.8834]\n",
            "--- Class contradiction_1 accuracy: 0.9702]\n",
            "--- Class entailment_0 accuracy: 0.8878]\n",
            "--- Class entailment_1 accuracy: 0.8571]\n",
            "--- Class neutral_0 accuracy: 0.8449]\n",
            "--- Class neutral_1 accuracy: 0.6782]\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate_roberta(roberta, roberta_val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### BERT + ALBERT Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "OfhYO7Db4_fB"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "negation_dict = {0: 'entailment_0',\n",
        " 1: 'entailment_1',\n",
        " 2: 'contradiction_0',\n",
        " 3: 'contradiction_1',\n",
        " 4: 'neutral_0',\n",
        " 5: 'neutral_1'}\n",
        "\n",
        "def multi_acc(y_pred, y_test):\n",
        "  acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
        "  return acc\n",
        "\n",
        "def evaluate_bert_albert(bert, albert, bert_val_loader, albert_val_loader, ensemble_weights=[0.5,0.5]):  \n",
        "  bert.eval()\n",
        "  albert.eval()\n",
        "  total_val_acc  = 0\n",
        "  total_val_loss = 0\n",
        "\n",
        "  class_correct_predictions = defaultdict(int)\n",
        "  class_total_predictions = defaultdict(int)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch_bert, batch_albert in tqdm(zip(bert_val_loader, albert_val_loader), total=min(len(bert_val_loader), len(albert_val_loader))):\n",
        "      # BERT\n",
        "      b_pair_token_ids, b_mask_ids, b_seg_ids, b_y, b_n = batch_bert\n",
        "      b_pair_token_ids = b_pair_token_ids.to(device)\n",
        "      b_mask_ids = b_mask_ids.to(device)\n",
        "      b_seg_ids = b_seg_ids.to(device)\n",
        "      b_labels = b_y.to(device)\n",
        "      b_negation = b_n.to(device)\n",
        "\n",
        "      b_loss, b_logits = bert(b_pair_token_ids, \n",
        "                            token_type_ids=b_seg_ids, \n",
        "                            attention_mask=b_mask_ids, \n",
        "                            labels=b_labels).values()\n",
        "      b_probs = torch.softmax(b_logits, dim=1)\n",
        "      # b_preds = torch.argmax(b_probs, dim=1)\n",
        "      \n",
        "      # ALBERT\n",
        "      a_pair_token_ids, a_mask_ids, a_seg_ids, a_y, a_n = batch_albert\n",
        "      a_pair_token_ids = a_pair_token_ids.to(device)\n",
        "      a_mask_ids = a_mask_ids.to(device)\n",
        "      a_seg_ids = a_seg_ids.to(device)\n",
        "      a_labels = a_y.to(device)\n",
        "      a_negation = a_n.to(device)\n",
        "      a_loss, a_logits = albert(a_pair_token_ids, \n",
        "                                token_type_ids=a_seg_ids, \n",
        "                                attention_mask=a_mask_ids, \n",
        "                                labels=a_labels).values()\n",
        "      a_probs = torch.softmax(a_logits, dim=1)\n",
        "\n",
        "      # Weighted Majority Voting Attempt\n",
        "      # a_preds = torch.argmax(a_probs, dim=1)\n",
        "      # ensemble_preds = torch.zeros_like(b_labels)\n",
        "      # Compute weighted votes for each class and decide the final prediction\n",
        "      # for i in range(b_labels.size(0)):\n",
        "      #   votes = defaultdict(float)\n",
        "      #   votes[b_preds[i].item()] += ensemble_weights[0]\n",
        "      #   votes[a_preds[i].item()] += ensemble_weights[1]\n",
        "      #   ensemble_preds[i] = max(votes, key=votes.get)\n",
        "\n",
        "      # Apply weights to probabilities \n",
        "      ensemble_probs = a_probs * ensemble_weights[0] + b_probs * ensemble_weights[1]\n",
        "      ensemble_preds = torch.argmax(ensemble_probs, dim=1)\n",
        "\n",
        "      # Compute accuracy per negation class\n",
        "      for i in range(len(a_labels)):\n",
        "        label_name = 'entailment' if a_labels[i] == 0 else 'contradiction' if a_labels[i] == 1 else 'neutral'\n",
        "        class_identifier = negation_dict[int(a_negation[i].item())]\n",
        "        class_correct_predictions[class_identifier] += int(ensemble_preds[i] == a_labels[i])\n",
        "        class_total_predictions[class_identifier] += 1\n",
        "\n",
        "      correct_preds = (ensemble_preds == a_labels.to(device)).sum().item() / float(a_labels.size(0))\n",
        "      total_val_acc += correct_preds\n",
        "      total_val_loss += (b_loss.item() + a_loss.item())/2\n",
        "\n",
        "    val_acc  = total_val_acc/len(bert_val_loader)\n",
        "    val_loss = total_val_loss/len(bert_val_loader)\n",
        "  \n",
        "    print(f'Test_loss: {val_loss:.4f} Test_acc: {val_acc:.4f}')\n",
        "\n",
        "    for class_id, correct_count in sorted(class_correct_predictions.items()):\n",
        "      accuracy = correct_count / class_total_predictions[class_id]\n",
        "      print(f\"--- Class {class_id} accuracy: {accuracy:.4f}]\")\n",
        "    print('\\n')\n",
        "\n",
        "  return float(val_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### BERT + RoBERTa Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "negation_dict = {0: 'entailment_0',\n",
        " 1: 'entailment_1',\n",
        " 2: 'contradiction_0',\n",
        " 3: 'contradiction_1',\n",
        " 4: 'neutral_0',\n",
        " 5: 'neutral_1'}\n",
        "\n",
        "def multi_acc(y_pred, y_test):\n",
        "  acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
        "  return acc\n",
        "\n",
        "def evaluate_bert_roberta(bert, roberta, bert_test_loader, roberta_test_loader, ensemble_weights=[0.5,0.5]):  \n",
        "  bert.eval()\n",
        "  roberta.eval()\n",
        "  total_val_acc  = 0\n",
        "  total_val_loss = 0\n",
        "\n",
        "  class_correct_predictions = defaultdict(int)\n",
        "  class_total_predictions = defaultdict(int)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch_bert, batch_roberta in tqdm(zip(bert_test_loader, roberta_test_loader), total=min(len(bert_test_loader), len(roberta_test_loader))):\n",
        "      # BERT\n",
        "      b_pair_token_ids, b_mask_ids, b_seg_ids, b_y, b_n = batch_bert\n",
        "      b_pair_token_ids = b_pair_token_ids.to(device)\n",
        "      b_mask_ids = b_mask_ids.to(device)\n",
        "      b_seg_ids = b_seg_ids.to(device)\n",
        "      b_labels = b_y.to(device)\n",
        "      b_negation = b_n.to(device)\n",
        "\n",
        "      b_loss, b_logits = bert(b_pair_token_ids, \n",
        "                            token_type_ids=b_seg_ids, \n",
        "                            attention_mask=b_mask_ids, \n",
        "                            labels=b_labels).values()\n",
        "      b_probs = torch.softmax(b_logits, dim=1)\n",
        "      \n",
        "      # ALBERT\n",
        "      r_pair_token_ids, r_mask_ids, r_y, r_n = batch_roberta\n",
        "      r_pair_token_ids = r_pair_token_ids.to(device)\n",
        "      r_mask_ids = r_mask_ids.to(device)\n",
        "      r_labels = r_y.to(device)\n",
        "      r_negation = r_n.to(device)\n",
        "\n",
        "      r_loss, r_logits = roberta(r_pair_token_ids, \n",
        "                                attention_mask=r_mask_ids, \n",
        "                                labels=r_labels).values()\n",
        "      r_probs = torch.softmax(r_logits, dim=1)\n",
        "      \n",
        "      ensemble_probs = ensemble_weights[0] * b_probs + ensemble_weights[1] * r_probs\n",
        "      ensemble_preds = torch.argmax(ensemble_probs, dim=1)\n",
        "\n",
        "      # Compute accuracy per negation class\n",
        "      for i in range(len(b_labels)):\n",
        "        label_name = 'entailment' if b_labels[i] == 0 else 'contradiction' if b_labels[i] == 1 else 'neutral'\n",
        "        class_identifier = negation_dict[int(b_negation[i].item())]\n",
        "        class_correct_predictions[class_identifier] += int(ensemble_preds[i] == b_labels[i])\n",
        "        class_total_predictions[class_identifier] += 1\n",
        "\n",
        "      correct_preds = (ensemble_preds == b_labels.to(device)).sum().item() / float(b_labels.size(0))\n",
        "      total_val_acc += correct_preds\n",
        "      total_val_loss += (b_loss.item() + b_loss.item())/2\n",
        "\n",
        "    val_acc  = total_val_acc/len(bert_val_loader)\n",
        "    val_loss = total_val_loss/len(bert_val_loader)\n",
        "  \n",
        "    print(f'Test_loss: {val_loss:.4f} Test_acc: {val_acc:.4f}')\n",
        "\n",
        "    for class_id, correct_count in sorted(class_correct_predictions.items()):\n",
        "      accuracy = correct_count / class_total_predictions[class_id]\n",
        "      print(f\"--- Class {class_id} accuracy: {accuracy:.4f}]\")\n",
        "    print('\\n')\n",
        "  \n",
        "  return float(val_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### BERT + ALBERT + RoBERTa Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "negation_dict = {0: 'entailment_0',\n",
        " 1: 'entailment_1',\n",
        " 2: 'contradiction_0',\n",
        " 3: 'contradiction_1',\n",
        " 4: 'neutral_0',\n",
        " 5: 'neutral_1'}\n",
        "\n",
        "def multi_acc(y_pred, y_test):\n",
        "  acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
        "  return acc\n",
        "\n",
        "def evaluate_bert_albert_roberta(bert, roberta, albert, bert_val_loader, roberta_val_loader, albert_val_loader, ensemble_weights=[0.5,0.5,0.5]):  \n",
        "  bert.eval()\n",
        "  roberta.eval()\n",
        "  albert.eval()\n",
        "  total_val_acc  = 0\n",
        "  total_val_loss = 0\n",
        "\n",
        "  class_correct_predictions = defaultdict(int)\n",
        "  class_total_predictions = defaultdict(int)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch_bert, batch_roberta, batch_albert in tqdm(zip(bert_val_loader, roberta_val_loader, albert_val_loader), total=min(len(bert_val_loader), len(roberta_val_loader))):\n",
        "      # BERT\n",
        "      b_pair_token_ids, b_mask_ids, b_seg_ids, b_y, b_n = batch_bert\n",
        "      b_pair_token_ids = b_pair_token_ids.to(device)\n",
        "      b_mask_ids = b_mask_ids.to(device)\n",
        "      b_seg_ids = b_seg_ids.to(device)\n",
        "      b_labels = b_y.to(device)\n",
        "      b_negation = b_n.to(device)\n",
        "\n",
        "      b_loss, b_logits = bert(b_pair_token_ids, \n",
        "                            token_type_ids=b_seg_ids, \n",
        "                            attention_mask=b_mask_ids, \n",
        "                            labels=b_labels).values()\n",
        "      b_probs = torch.softmax(b_logits, dim=1)\n",
        "      \n",
        "      # ALBERT\n",
        "      r_pair_token_ids, r_mask_ids, r_y, r_n = batch_roberta\n",
        "      r_pair_token_ids = r_pair_token_ids.to(device)\n",
        "      r_mask_ids = r_mask_ids.to(device)\n",
        "      r_labels = r_y.to(device)\n",
        "      r_negation = r_n.to(device)\n",
        "\n",
        "      r_loss, r_logits = roberta(r_pair_token_ids, \n",
        "                                attention_mask=r_mask_ids, \n",
        "                                labels=r_labels).values()\n",
        "      r_probs = torch.softmax(r_logits, dim=1)\n",
        "\n",
        "\n",
        "      # ALBERT\n",
        "      a_pair_token_ids, a_mask_ids, a_seg_ids, a_y, a_n = batch_albert\n",
        "      a_pair_token_ids = a_pair_token_ids.to(device)\n",
        "      a_mask_ids = a_mask_ids.to(device)\n",
        "      a_seg_ids = a_seg_ids.to(device)\n",
        "      a_labels = a_y.to(device)\n",
        "      a_negation = a_n.to(device)\n",
        "\n",
        "      a_loss, a_logits = albert(a_pair_token_ids, \n",
        "                                token_type_ids=a_seg_ids, \n",
        "                                attention_mask=a_mask_ids, \n",
        "                                labels=a_labels).values()\n",
        "      a_probs = torch.softmax(a_logits, dim=1)\n",
        "\n",
        "      \n",
        "      ensemble_probs = ensemble_weights[0] * b_probs + ensemble_weights[1] * a_probs + ensemble_weights[2] * r_probs\n",
        "      ensemble_preds = torch.argmax(ensemble_probs, dim=1)\n",
        "\n",
        "      # Compute accuracy per negation class\n",
        "      for i in range(len(b_labels)):\n",
        "        label_name = 'entailment' if b_labels[i] == 0 else 'contradiction' if b_labels[i] == 1 else 'neutral'\n",
        "        class_identifier = negation_dict[int(b_negation[i].item())]\n",
        "        class_correct_predictions[class_identifier] += int(ensemble_preds[i] == b_labels[i])\n",
        "        class_total_predictions[class_identifier] += 1\n",
        "\n",
        "      correct_preds = (ensemble_preds == b_labels.to(device)).sum().item() / float(b_labels.size(0))\n",
        "      total_val_acc += correct_preds\n",
        "      total_val_loss += (b_loss.item() + b_loss.item())/2\n",
        "\n",
        "    val_acc  = total_val_acc/len(bert_val_loader)\n",
        "    val_loss = total_val_loss/len(bert_val_loader)\n",
        "  \n",
        "    print(f'Test_loss: {val_loss:.4f} Test_acc: {val_acc:.4f}')\n",
        "\n",
        "    for class_id, correct_count in sorted(class_correct_predictions.items()):\n",
        "      accuracy = correct_count / class_total_predictions[class_id]\n",
        "      print(f\"--- Class {class_id} accuracy: {accuracy:.4f}]\")\n",
        "    print('\\n')\n",
        "\n",
        "  return float(val_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Grid Search for Best Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weights = BERT 0.1, ROBERTA 0.9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1227/1227 [01:22<00:00, 14.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_loss: 0.5864 Test_acc: 0.8774\n",
            "--- Class contradiction_0 accuracy: 0.8859]\n",
            "--- Class contradiction_1 accuracy: 0.9722]\n",
            "--- Class entailment_0 accuracy: 0.8875]\n",
            "--- Class entailment_1 accuracy: 0.8462]\n",
            "--- Class neutral_0 accuracy: 0.8488]\n",
            "--- Class neutral_1 accuracy: 0.7011]\n",
            "\n",
            "\n",
            "Weights = BERT 0.2, ROBERTA 0.8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1227/1227 [01:22<00:00, 14.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_loss: 0.5864 Test_acc: 0.8788\n",
            "--- Class contradiction_0 accuracy: 0.8852]\n",
            "--- Class contradiction_1 accuracy: 0.9722]\n",
            "--- Class entailment_0 accuracy: 0.8864]\n",
            "--- Class entailment_1 accuracy: 0.8462]\n",
            "--- Class neutral_0 accuracy: 0.8547]\n",
            "--- Class neutral_1 accuracy: 0.7241]\n",
            "\n",
            "\n",
            "Weights = BERT 0.30000000000000004, ROBERTA 0.7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1227/1227 [01:22<00:00, 14.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_loss: 0.5864 Test_acc: 0.8786\n",
            "--- Class contradiction_0 accuracy: 0.8852]\n",
            "--- Class contradiction_1 accuracy: 0.9722]\n",
            "--- Class entailment_0 accuracy: 0.8837]\n",
            "--- Class entailment_1 accuracy: 0.8462]\n",
            "--- Class neutral_0 accuracy: 0.8574]\n",
            "--- Class neutral_1 accuracy: 0.7126]\n",
            "\n",
            "\n",
            "Weights = BERT 0.4, ROBERTA 0.6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1227/1227 [01:22<00:00, 14.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_loss: 0.5864 Test_acc: 0.8786\n",
            "--- Class contradiction_0 accuracy: 0.8867]\n",
            "--- Class contradiction_1 accuracy: 0.9762]\n",
            "--- Class entailment_0 accuracy: 0.8799]\n",
            "--- Class entailment_1 accuracy: 0.8242]\n",
            "--- Class neutral_0 accuracy: 0.8613]\n",
            "--- Class neutral_1 accuracy: 0.6782]\n",
            "\n",
            "\n",
            "Weights = BERT 0.5, ROBERTA 0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1227/1227 [01:22<00:00, 14.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_loss: 0.5864 Test_acc: 0.8707\n",
            "--- Class contradiction_0 accuracy: 0.8800]\n",
            "--- Class contradiction_1 accuracy: 0.9702]\n",
            "--- Class entailment_0 accuracy: 0.8660]\n",
            "--- Class entailment_1 accuracy: 0.8132]\n",
            "--- Class neutral_0 accuracy: 0.8587]\n",
            "--- Class neutral_1 accuracy: 0.6667]\n",
            "\n",
            "\n",
            "Weights = BERT 0.6, ROBERTA 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1227/1227 [01:22<00:00, 14.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_loss: 0.5864 Test_acc: 0.8570\n",
            "--- Class contradiction_0 accuracy: 0.8597]\n",
            "--- Class contradiction_1 accuracy: 0.9683]\n",
            "--- Class entailment_0 accuracy: 0.8539]\n",
            "--- Class entailment_1 accuracy: 0.8022]\n",
            "--- Class neutral_0 accuracy: 0.8468]\n",
            "--- Class neutral_1 accuracy: 0.6552]\n",
            "\n",
            "\n",
            "Weights = BERT 0.7000000000000001, ROBERTA 0.29999999999999993\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1227/1227 [01:22<00:00, 14.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_loss: 0.5864 Test_acc: 0.8487\n",
            "--- Class contradiction_0 accuracy: 0.8549]\n",
            "--- Class contradiction_1 accuracy: 0.9583]\n",
            "--- Class entailment_0 accuracy: 0.8442]\n",
            "--- Class entailment_1 accuracy: 0.7912]\n",
            "--- Class neutral_0 accuracy: 0.8376]\n",
            "--- Class neutral_1 accuracy: 0.6437]\n",
            "\n",
            "\n",
            "Weights = BERT 0.8, ROBERTA 0.19999999999999996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1227/1227 [01:22<00:00, 14.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_loss: 0.5864 Test_acc: 0.8414\n",
            "--- Class contradiction_0 accuracy: 0.8450]\n",
            "--- Class contradiction_1 accuracy: 0.9563]\n",
            "--- Class entailment_0 accuracy: 0.8377]\n",
            "--- Class entailment_1 accuracy: 0.7802]\n",
            "--- Class neutral_0 accuracy: 0.8307]\n",
            "--- Class neutral_1 accuracy: 0.6437]\n",
            "\n",
            "\n",
            "Weights = BERT 0.9, ROBERTA 0.09999999999999998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1227/1227 [01:22<00:00, 14.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_loss: 0.5864 Test_acc: 0.8367\n",
            "--- Class contradiction_0 accuracy: 0.8394]\n",
            "--- Class contradiction_1 accuracy: 0.9484]\n",
            "--- Class entailment_0 accuracy: 0.8344]\n",
            "--- Class entailment_1 accuracy: 0.7802]\n",
            "--- Class neutral_0 accuracy: 0.8254]\n",
            "--- Class neutral_1 accuracy: 0.6437]\n",
            "\n",
            "\n",
            "[0.2, 0.8]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "step = 0.1\n",
        "best_score = 0.0\n",
        "for bert_weight in np.arange(0.1, 0.9 + step, step):\n",
        "    roberta_weight = 1 - bert_weight\n",
        "    print(f\"Weights = BERT {bert_weight}, ROBERTA {roberta_weight}\")\n",
        "    score = evaluate_bert_roberta(bert, roberta, bert_val_loader, roberta_val_loader, ensemble_weights=[bert_weight, roberta_weight])\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_weights = [bert_weight, roberta_weight]\n",
        "\n",
        "print(best_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weights = BERT 0.1, ALBERT 0.9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1227/1227 [01:32<00:00, 13.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_loss: 0.5206 Test_acc: 0.8367\n",
            "--- Class contradiction_0 accuracy: 0.8372]\n",
            "--- Class contradiction_1 accuracy: 0.9484]\n",
            "--- Class entailment_0 accuracy: 0.8335]\n",
            "--- Class entailment_1 accuracy: 0.7912]\n",
            "--- Class neutral_0 accuracy: 0.8281]\n",
            "--- Class neutral_1 accuracy: 0.6437]\n",
            "\n",
            "\n",
            "Weights = BERT 0.2, ALBERT 0.8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1227/1227 [01:32<00:00, 13.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_loss: 0.5206 Test_acc: 0.8399\n",
            "--- Class contradiction_0 accuracy: 0.8431]\n",
            "--- Class contradiction_1 accuracy: 0.9544]\n",
            "--- Class entailment_0 accuracy: 0.8338]\n",
            "--- Class entailment_1 accuracy: 0.8022]\n",
            "--- Class neutral_0 accuracy: 0.8317]\n",
            "--- Class neutral_1 accuracy: 0.6437]\n",
            "\n",
            "\n",
            "Weights = BERT 0.30000000000000004, ALBERT 0.7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1227/1227 [01:32<00:00, 13.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_loss: 0.5206 Test_acc: 0.8441\n",
            "--- Class contradiction_0 accuracy: 0.8450]\n",
            "--- Class contradiction_1 accuracy: 0.9563]\n",
            "--- Class entailment_0 accuracy: 0.8380]\n",
            "--- Class entailment_1 accuracy: 0.8022]\n",
            "--- Class neutral_0 accuracy: 0.8386]\n",
            "--- Class neutral_1 accuracy: 0.6437]\n",
            "\n",
            "\n",
            "Weights = BERT 0.4, ALBERT 0.6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1227/1227 [01:32<00:00, 13.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_loss: 0.5206 Test_acc: 0.8496\n",
            "--- Class contradiction_0 accuracy: 0.8483]\n",
            "--- Class contradiction_1 accuracy: 0.9623]\n",
            "--- Class entailment_0 accuracy: 0.8439]\n",
            "--- Class entailment_1 accuracy: 0.8022]\n",
            "--- Class neutral_0 accuracy: 0.8458]\n",
            "--- Class neutral_1 accuracy: 0.6437]\n",
            "\n",
            "\n",
            "Weights = BERT 0.5, ALBERT 0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1227/1227 [01:32<00:00, 13.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_loss: 0.5206 Test_acc: 0.8565\n",
            "--- Class contradiction_0 accuracy: 0.8571]\n",
            "--- Class contradiction_1 accuracy: 0.9623]\n",
            "--- Class entailment_0 accuracy: 0.8509]\n",
            "--- Class entailment_1 accuracy: 0.7912]\n",
            "--- Class neutral_0 accuracy: 0.8528]\n",
            "--- Class neutral_1 accuracy: 0.6437]\n",
            "\n",
            "\n",
            "Weights = BERT 0.6, ALBERT 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1227/1227 [01:32<00:00, 13.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_loss: 0.5206 Test_acc: 0.8548\n",
            "--- Class contradiction_0 accuracy: 0.8501]\n",
            "--- Class contradiction_1 accuracy: 0.9583]\n",
            "--- Class entailment_0 accuracy: 0.8515]\n",
            "--- Class entailment_1 accuracy: 0.7582]\n",
            "--- Class neutral_0 accuracy: 0.8534]\n",
            "--- Class neutral_1 accuracy: 0.6782]\n",
            "\n",
            "\n",
            "Weights = BERT 0.7000000000000001, ALBERT 0.29999999999999993\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1227/1227 [01:32<00:00, 13.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_loss: 0.5206 Test_acc: 0.8537\n",
            "--- Class contradiction_0 accuracy: 0.8490]\n",
            "--- Class contradiction_1 accuracy: 0.9524]\n",
            "--- Class entailment_0 accuracy: 0.8492]\n",
            "--- Class entailment_1 accuracy: 0.7582]\n",
            "--- Class neutral_0 accuracy: 0.8538]\n",
            "--- Class neutral_1 accuracy: 0.7011]\n",
            "\n",
            "\n",
            "Weights = BERT 0.8, ALBERT 0.19999999999999996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1227/1227 [01:32<00:00, 13.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_loss: 0.5206 Test_acc: 0.8500\n",
            "--- Class contradiction_0 accuracy: 0.8453]\n",
            "--- Class contradiction_1 accuracy: 0.9484]\n",
            "--- Class entailment_0 accuracy: 0.8445]\n",
            "--- Class entailment_1 accuracy: 0.7582]\n",
            "--- Class neutral_0 accuracy: 0.8511]\n",
            "--- Class neutral_1 accuracy: 0.7011]\n",
            "\n",
            "\n",
            "Weights = BERT 0.9, ALBERT 0.09999999999999998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1227/1227 [01:32<00:00, 13.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_loss: 0.5206 Test_acc: 0.8485\n",
            "--- Class contradiction_0 accuracy: 0.8402]\n",
            "--- Class contradiction_1 accuracy: 0.9524]\n",
            "--- Class entailment_0 accuracy: 0.8421]\n",
            "--- Class entailment_1 accuracy: 0.7802]\n",
            "--- Class neutral_0 accuracy: 0.8514]\n",
            "--- Class neutral_1 accuracy: 0.7241]\n",
            "\n",
            "\n",
            "[0.5, 0.5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "step = 0.1\n",
        "best_score = 0.0\n",
        "for bert_weight in np.arange(0.1, 0.9 + step, step):\n",
        "    albert_weight = 1 - bert_weight\n",
        "    print(f\"Weights = BERT {bert_weight}, ALBERT {albert_weight}\")\n",
        "    score = evaluate_bert_albert(bert, albert, bert_val_loader, albert_val_loader, ensemble_weights=[bert_weight, albert_weight])\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_weights = [bert_weight, albert_weight]\n",
        "\n",
        "print(best_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1227/1227 [02:12<00:00,  9.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test_loss: 0.5864 Test_acc: 0.8783\n",
            "--- Class contradiction_0 accuracy: 0.8811]\n",
            "--- Class contradiction_1 accuracy: 0.9762]\n",
            "--- Class entailment_0 accuracy: 0.8751]\n",
            "--- Class entailment_1 accuracy: 0.8242]\n",
            "--- Class neutral_0 accuracy: 0.8696]\n",
            "--- Class neutral_1 accuracy: 0.7126]\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.878347304692048"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_bert_albert_roberta(bert, roberta, albert, bert_val_loader, roberta_val_loader, albert_val_loader, ensemble_weights=[0.5,0.5,0.5])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Sentence Entailment BERT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
